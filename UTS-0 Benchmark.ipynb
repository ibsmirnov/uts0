{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a09d5-b2f7-4b9b-b344-97b3a24a7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sdgclassification-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35085d3c-3959-49c2-b4ba-6d794e0a6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This is a very simple wrapper to store text embeddings\n",
    "class VectorDB:\n",
    "    def __init__(self, key, file_name = False):\n",
    "        self.client = OpenAI(api_key=key)\n",
    "\n",
    "        if file_name:\n",
    "            self.db = pickle.load(open(file_name + '.p', 'rb'))\n",
    "        else:\n",
    "            self.db = {}\n",
    "\n",
    "    def load_vectors(self, texts):\n",
    "        for text in tqdm(texts):\n",
    "            if text in self.db: continue\n",
    "            response = self.client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "            self.db[text] = response.data[0].embedding\n",
    "\n",
    "    def get_sim(self, text1, text2):\n",
    "        return self.cossim(self.db[text1], self.db[text2])\n",
    "\n",
    "    def cossim(self, a, b):\n",
    "        return np.dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "    def save(self, file_name):\n",
    "        pickle.dump(self.db, open(file_name + '.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6397457e-9c7b-4043-893b-677bbab2467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdgclassification.benchmark import Benchmark\n",
    "\n",
    "# Loading SDG targets, cleaned from dates as dates seem to be irrelavant to classification task\n",
    "targets = pickle.load(open('targets.p', 'rb'))\n",
    "\n",
    "# Loading text embedding for targets and texts from benchamrk\n",
    "DB = VectorDB(False, 'db_vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198da8cb-b2e3-4500-8c98-45aad4e4a07e",
   "metadata": {},
   "source": [
    "The main issue with using similarity between text embeddings is that there is no natural threshold.\n",
    "\n",
    "Should a text be considered related to an SDG if the similarity is above 0.5? 0.1? 0.9?\n",
    "\n",
    "The thresholds below are selected to maximize accuracy, so they probably overestimate it.\n",
    "\n",
    "A proper approach would be to use part of the dataset to determine cutoffs and then compute accuracy on another. However, this particular benchmark is too small for that\\. Alternatively, the entire precision/recall curves could be compared between two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fa25b6-9da6-42ae-93f5-3b68404b301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.4244574244574244, 0.35448535448535445, 0.3784393784393784, 0.3233653233653233, 0.3743923743923744, 0.403058403058403, 0.39357439357439356, 0.36266536266536264, 0.39408739408739407, 0.36786736786736784, 0.41178041178041175, 0.4087314087314087, 0.4266624266624266]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dfe49-c094-49f4-803c-da8340317c92",
   "metadata": {},
   "source": [
    "To predict SDG, we first determine the target with the highest similarity.\n",
    "\n",
    "The idea is that if a text relates to one target, it is sufficient to be related to SDG.\n",
    "\n",
    "One could try using different thresholds for different targets, but that increases the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a5e1a3-7a2a-4d61-b0f9-b8270f1534a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sdgs(text):\n",
    "    result = []\n",
    "    for sdg in range(1, 14):\n",
    "        sim = np.max([DB.get_sim(text, target) for target in targets[sdg]])\n",
    "\n",
    "        if sim > thresholds[sdg - 1]:\n",
    "            result.append(sdg)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14650315-3ff2-4b2d-9beb-daf126cd4eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Running benchmark\n",
      "Results:\n",
      "+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+\n",
      "| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |\n",
      "|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|\n",
      "| Average | 74.2 |           87.5 |            85.1 |         90.5 |       0.88 |   33 |  5.8 | 31.8 |  3.5 |\n",
      "| 1       |   77 |           92.2 |            86.2 |         92.6 |       0.89 |   25 |    4 |   46 |    2 |\n",
      "| 2       |   69 |           85.5 |            85.7 |         93.3 |       0.89 |   42 |    7 |   17 |    3 |\n",
      "| 3       |   76 |           89.5 |            85.7 |         85.7 |       0.86 |   24 |    4 |   44 |    4 |\n",
      "| 4       |   82 |           86.6 |            82.0 |         95.3 |       0.88 |   41 |    9 |   30 |    2 |\n",
      "| 5       |   69 |           82.6 |            82.9 |         82.9 |       0.83 |   29 |    6 |   28 |    6 |\n",
      "| 6       |   85 |           88.2 |            89.6 |         89.6 |       0.90 |   43 |    5 |   32 |    5 |\n",
      "| 7       |  100 |           91.0 |            90.2 |         92.0 |       0.91 |   46 |    5 |   45 |    4 |\n",
      "| 8       |   74 |           82.4 |            75.5 |         97.4 |       0.85 |   37 |   12 |   24 |    1 |\n",
      "| 9       |   57 |           89.5 |            86.7 |         92.9 |       0.90 |   26 |    4 |   25 |    2 |\n",
      "| 10      |   61 |           91.8 |            87.5 |         96.6 |       0.92 |   28 |    4 |   28 |    1 |\n",
      "| 11      |   69 |           88.4 |            85.2 |         85.2 |       0.85 |   23 |    4 |   38 |    4 |\n",
      "| 12      |   80 |           78.8 |            82.5 |         76.7 |       0.80 |   33 |    7 |   30 |   10 |\n",
      "| 13      |   65 |           90.8 |            86.5 |         97.0 |       0.91 |   32 |    5 |   27 |    1 |\n",
      "+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+\n",
      "Benchmark completed\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "benchmark = Benchmark(predict_sdgs)\n",
    "benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69436fc-2cfd-4f01-89fb-b405b48be481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
